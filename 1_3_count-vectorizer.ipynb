{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente se va a realizar un preprocesado de los datos, eliminando ls palabras sin significado útil, los url y los signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing the dataset\n",
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    cleanText = ''\n",
    "    phrase = nlp(text)\n",
    "    for token in phrase:\n",
    "        if not token.is_stop and not token.is_punct and not token.like_url:\n",
    "            cleanText += ' ' + token.text\n",
    "\n",
    "    return cleanText\n",
    "\n",
    "df['text_cleaned'] = df['text'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Hi Roy hope ok Trans people gay thing s ramme...\n",
       "1                                     fuckin hell biology\n",
       "2                                  nice looking clergyman\n",
       "3                           AIDS WAY SIN CONSEQUENCES BAD\n",
       "4                                                   learn\n",
       "                              ...                        \n",
       "8143     Yeah alive time election happen fairly soon U...\n",
       "8144                                  fundamentally wrong\n",
       "8145     confused homosexuality big deal proud normal ...\n",
       "8146                                           disgusting\n",
       "8147     Peter Sørensen note Peter poor maths 13 27 eq...\n",
       "Name: text_cleaned, Length: 8148, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras el preprocesado de datos se va a usar CountVectorizer para transformar los tokens y Random Forest para realizar las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text_cleaned']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usa Grid Search para buscar los parámetros óptimos en la vectorización y en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define tu pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define los parámetros para la búsqueda \n",
    "parameters = {\n",
    "    'count_vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'count_vectorizer__max_features': [1000, 5000, None],\n",
    "    'clf__n_estimators': [50, 100, 200],  \n",
    "    'clf__max_depth': [None, 10, 20],  \n",
    "}\n",
    "\n",
    "# Realiza la búsqueda de hiperparámetros utilizando GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una nueva pipeline con los mejores parámetros encontrados\n",
    "best_pipeline = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "best_pipeline.set_params(**best_params)\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "predictions = best_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1445  255]\n",
      " [ 461  528]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80      1700\n",
      "           1       0.67      0.53      0.60       989\n",
      "\n",
      "    accuracy                           0.73      2689\n",
      "   macro avg       0.72      0.69      0.70      2689\n",
      "weighted avg       0.73      0.73      0.73      2689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7337300111565638"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se consigue una precisión muy baja, muy paredida al sisyema que utiliza TF-IDF y LinearSVC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
